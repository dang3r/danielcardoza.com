<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Project on dan&#39;s internet pad</title>
    <link>/tags/project/</link>
    <description>Recent content in Project on dan&#39;s internet pad</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 06 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/project/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using ffmpeg to generate a lifting compilation video</title>
      <link>/ffmpeg-lifting/</link>
      <pubDate>Sun, 06 Apr 2025 00:00:00 +0000</pubDate>
      <guid>/ffmpeg-lifting/</guid>
      <description>&lt;p&gt;I have a friend who is my (power)lifting coach. Coaches and trainers are very useful for exercise selection, bouncing new ideas off of and to help guide you along. Improving one&amp;rsquo;s lifting numbers is non-linear and I love having someone I can always discuss approaches with. Results boil down to the usual suspects (eg. consistency, intensity, recovery, etc.) but i&amp;rsquo;ve found it very beneficial.&lt;/p&gt;&#xA;&lt;p&gt;We use a spreadsheet to communicate exercises, and numbers for the each training week. At the end of each week, I send an email with all of my lifts, notes and videos of specific lifts. The videos reside on Google Photos and I generate a shareable link, embed it in the email and share it with him. This has worked fine, but didn&amp;rsquo;t feel &lt;em&gt;great&lt;/em&gt;. Why not make a single video containing all weekly lifts instead of having him click on links to short clips? I did not want to do this with a video editor, and thus began my dive into &lt;code&gt;ffmpeg&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adventures with Math Academy</title>
      <link>/math_academy/</link>
      <pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate>
      <guid>/math_academy/</guid>
      <description>&lt;h1 id=&#34;adventures-with-math-academy&#34;&gt;Adventures with Math Academy&lt;/h1&gt;&#xA;&lt;p&gt;Last year, I learned about &lt;a href=&#34;https://mathacademy.com/&#34;&gt;MathAcademy.com&lt;/a&gt;. It is a website that helps you learn math in a cooler way. Imagine you had a graph of all mathematical knowledge where the nodes are concepts and the edges represents prerequisites/dependencies. With that graph, if you learn a new concept you can determine what new ones to learn. Imagine creating a queue of new concepts to to learn by identifying adjacent child nodes to nodes whose concept you already know. Also, imagine the cool spaced repetition and other learning techniques you can apply by adding labels to a given node indicating when you last reviewed the concept and were proficient in it! Follow &lt;a href=&#34;https://github.com/dang3r/forge/blob/master/mathacademy/factoring.py&#34;&gt;Justin Skycak&lt;/a&gt; for more information. I love his blog.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google Data Studio : Powerful and easy data visualization</title>
      <link>/google-data-studio/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      <guid>/google-data-studio/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;&#xA;&lt;p&gt;Google Data Studio is a tool engineers and analysts can use to visualize and&#xA;present data.  It is the equivalent of using Excel or Google Sheets to generate&#xA;graphs and plots but for data in different data stores (eg. Google BigQuery).&lt;/p&gt;&#xA;&lt;p&gt;I became acquainted with Data Studio through work. I had a large dataset and results from&#xA;a very large processing job that I wanted to turn into a report. The data was in&#xA;Google BigQuery, a datawarehouse on GCP. In the past, my workflow may have been&#xA;to:&lt;/p&gt;</description>
    </item>
    <item>
      <title>aws-manifest</title>
      <link>/aws-manifest/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/aws-manifest/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL:DR&lt;/strong&gt; &lt;code&gt;pip install aws-manifest&lt;/code&gt; / &lt;a href=&#34;https://github.com/dang3r/aws-manifest&#34;&gt;https://github.com/dang3r/aws-manifest&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;I recently needed to retrieve a list of all Amazon Web Services (AWS) services, and&#xA;actions that could be called on them. I wanted to answer questions such as &amp;ldquo;What&#xA;are all of the api actions that can be done for ec2?&amp;rdquo;.&lt;/p&gt;&#xA;&lt;p&gt;There is no API for doing so from AWS, so I started looking for other options.&#xA;Some projects scrape the AWS documentation and extract the data from the markup.&#xA;This is how projects like &lt;a href=&#34;https://iam.cloudonaut.io/&#34;&gt;https://iam.cloudonaut.io/&lt;/a&gt; work. You can see the code they use&#xA;for scraping and parsing in their github repo &lt;a href=&#34;https://github.com/widdix/complete-aws-iam-reference/tree/master/tools&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stratocumulus.cloud</title>
      <link>/stratocumulus/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      <guid>/stratocumulus/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL:DR&lt;/strong&gt; &lt;a href=&#34;https://stratocumulus.cloud&#34;&gt;https://stratocumulus.cloud&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;top-level-domains-tld&#34;&gt;Top level domains (TLD)&lt;/h1&gt;&#xA;&lt;p&gt;Every so often, I encounter a new top level domain (TLD). TLDs are at the&#xA;topmost level of domains. A few of the most common are &lt;code&gt;.com&lt;/code&gt;, &lt;code&gt;.org&lt;/code&gt;, &lt;code&gt;.net&lt;/code&gt; and if&#xA;you are a trendy startup, &lt;code&gt;.io&lt;/code&gt;. You can retrieve a full list of TLDs on&#xA;&lt;a href=&#34;https://en.wikipedia.org/wiki/Top-level_domain&#34;&gt;wikipedia&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Below are some of my favourite TLDs with various subdomains.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;.ninja&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;coding.ninja&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sneaky.ninja&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;food.ninja&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;.rocks&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;exercise.rocks&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;igneous.rocks&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ilove.rocks&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;.life&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;thegood.life&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;theeasy.life&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;simple.life&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;.news&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;fake.news&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;real.news&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;thegood.news&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;When a new TLD comes out, most of the interesting domains are snatched up quite quickly.&#xA;Sometimes, you can actually bid and pay extra to receive early access. Google did this&#xA;with &lt;code&gt;.dev&lt;/code&gt; domain earlier this &lt;a href=&#34;https://insights.dice.com/2019/02/19/google-launches-dev-domain-early-access/&#34;&gt;year&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clickupy - API &#43; FUSE for Clickup</title>
      <link>/clickup/</link>
      <pubDate>Sun, 26 May 2019 00:00:00 +0000</pubDate>
      <guid>/clickup/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL:DR&lt;/strong&gt; &lt;code&gt;pip install clickupy&lt;/code&gt; / &lt;a href=&#34;https://github.com/dang3r/clickupy&#34;&gt;https://github.com/dang3r/clickupy&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Over the past few years, I have used many different project management tools.&#xA;JIRA has been a consistent one, and the tool with the most name recognition.&#xA;Trello is a very lightweight alternative, and the the one I personally use.&#xA;Redbooth is another big player and I&amp;rsquo;ve used it heavily (especially while working&#xA;there!). Wrike and Asana are a few others I&amp;rsquo;ve encountered every now and then.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wikireducer : Following Wikipedia links</title>
      <link>/wikio/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/wikio/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;I came back from the gym last week and a few of my friend&amp;rsquo;s made the following&#xA;claim:&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Following the first link of a Wikipedia article always leads to philosophy&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;It was a very strong claim, but one that can be verified easily.&lt;/p&gt;&#xA;&lt;h1 id=&#34;solution&#34;&gt;Solution&lt;/h1&gt;&#xA;&lt;p&gt;My previous scraping projects and linksearchers have been exclusively in Python.&#xA;I love Python, but I have been exposed to Ruby over the past months and decided&#xA;this project would be a good fit. 5 months ago I made&#xA;&lt;a href=&#34;https://github.com/dang3r/seguridad&#34;&gt;Seguridad&lt;/a&gt; to learn how to make a Ruby gem&#xA;and increase my exposure to the language. I was hoping to do the same this time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jenophone : SMS forwarder using Twilio</title>
      <link>/jenophone/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/jenophone/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;When I moved to California after graduation, it became difficult to easily&#xA;communicate with my girlfriend in Canada because of telecom issues.&lt;/p&gt;&#xA;&lt;p&gt;The crux of the problem was the following:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;My phone plan has unlimited data and unlimited texting to US, Canada phone&#xA;numbers.&lt;/li&gt;&#xA;&lt;li&gt;My girlfriend&amp;rsquo;s phone plan had limited data (thank you Canadian telecoms) and&#xA;only had unlimited texting in Canada.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;I wanted to make communication easier between us, so I decided to make my own&#xA;SMS forwarding service using Twilio.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cerca : Search a website&#39;s links</title>
      <link>/cerca/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      <guid>/cerca/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;I recently had a problem where I wanted to verify that a website:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;did not link to a given website on a blacklist&lt;/li&gt;&#xA;&lt;li&gt;did not return non 2XX status codes for a given route&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Although there are many utilities you can probably piece together to solve this&#xA;problem, I decided to make my own utility &lt;code&gt;Cerca&lt;/code&gt; (which is Catalan for search).&lt;/p&gt;&#xA;&lt;h1 id=&#34;problem&#34;&gt;Problem&lt;/h1&gt;&#xA;&lt;p&gt;Given a website URL, search the website for all external and internal&#xA;links. Follow all internal links while not revisiting past links.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
